{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install torch transformers datasets\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-08T15:45:40.801240Z","iopub.execute_input":"2025-08-08T15:45:40.801798Z","iopub.status.idle":"2025-08-08T15:45:44.453077Z","shell.execute_reply.started":"2025-08-08T15:45:40.801775Z","shell.execute_reply":"2025-08-08T15:45:44.451929Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# enhanced_gpt_moe_training.py\nimport os\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom datasets import load_dataset\nfrom transformers import GPT2Tokenizer\nfrom torch.amp import autocast, GradScaler\n\n# -----------------------\n# Environment and device\n# -----------------------\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\"\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {device}\")\n\n# -----------------------\n# Model / training config\n# -----------------------\nMODEL_CONFIG = {\n    \"dim\": 512,\n    \"depth\": 8,\n    \"heads\": 8,\n    \"num_experts\": 12,\n    \"k\": 2,\n    \"max_len\": 512,\n    \"dropout\": 0.1,\n    \"moe_expansion\": 2.0\n}\n\nTRAINING_CONFIG = {\n    \"seq_len\": 256,\n    \"batch_size\": 1,\n    \"epochs\": 6,\n    \"lr\": 3e-4,\n    \"weight_decay\": 0.1,\n    \"betas\": (0.9, 0.95),\n    \"cosine_Tmax\": 6,\n    \"empty_cache_every\": 200\n}\n\n# -----------------------\n# Rotary embeddings\n# -----------------------\nclass RotaryEmbedding(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2).float() / dim))\n        self.register_buffer(\"inv_freq\", inv_freq)\n\n    def forward(self, x, seq_len=None):\n        if seq_len is None:\n            seq_len = x.shape[-2]\n        t = torch.arange(seq_len, device=x.device, dtype=self.inv_freq.dtype)\n        freqs = torch.outer(t, self.inv_freq)            # (seq_len, dim/2)\n        emb = torch.cat((freqs, freqs), dim=-1)         # (seq_len, dim)\n        return emb.cos().to(x.dtype), emb.sin().to(x.dtype)\n\ndef apply_rotary_pos_emb(q, k, cos, sin):\n    # q,k: (..., head_dim)\n    def rotate_half(x):\n        x1, x2 = x[..., : x.shape[-1] // 2], x[..., x.shape[-1] // 2 :]\n        return torch.cat((-x2, x1), dim=-1)\n    q_embed = (q * cos) + (rotate_half(q) * sin)\n    k_embed = (k * cos) + (rotate_half(k) * sin)\n    return q_embed, k_embed\n\n# -----------------------\n# SwiGLU FFN and Expert\n# -----------------------\nclass SwiGLU(nn.Module):\n    def __init__(self, dim, hidden_dim, dropout=0.1):\n        super().__init__()\n        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n        self.drop = nn.Dropout(dropout)\n\n    def forward(self, x):\n        return self.drop(self.w2(F.silu(self.w1(x)) * self.w3(x)))\n\nclass Expert(nn.Module):\n    def __init__(self, dim, hidden_dim, dropout=0.1):\n        super().__init__()\n        self.ffn = SwiGLU(dim, hidden_dim, dropout)\n    def forward(self, x):\n        return self.ffn(x)\n\n# -----------------------\n# Router (Top-k)\n# -----------------------\nclass TopKRouter(nn.Module):\n    def __init__(self, dim, num_experts, k=2, jitter=0.01):\n        super().__init__()\n        self.k = k\n        self.num_experts = num_experts\n        self.jitter = jitter\n        self.gate = nn.Linear(dim, num_experts, bias=False)\n        nn.init.normal_(self.gate.weight, 0, 0.1)\n\n    def forward(self, x):\n        # x: (B,T,D)\n        if self.training and self.jitter > 0:\n            x = x + torch.randn_like(x) * self.jitter\n        logits = self.gate(x)  # (B,T,E)\n        topk_vals, topk_idx = torch.topk(logits, self.k, dim=-1)  # (B,T,k)\n        weights = torch.zeros_like(logits, dtype=topk_vals.dtype)  # (B,T,E)\n        soft = F.softmax(topk_vals, dim=-1).to(logits.dtype)  # match weights dtype\n        weights = torch.zeros_like(logits)                   # no need to force dtype here\n        weights.scatter_(-1, topk_idx, soft)\n        return weights, topk_idx  # weights: (B,T,E); topk_idx: (B,T,k)\n\n# -----------------------\n# MoE Layer (memory-efficient)\n# -----------------------\nclass MoELayer(nn.Module):\n    def __init__(self, dim, hidden_dim, num_experts, k, dropout=0.1):\n        super().__init__()\n        self.router = TopKRouter(dim, num_experts, k)\n        self.experts = nn.ModuleList([Expert(dim, hidden_dim, dropout) for _ in range(num_experts)])\n        self.num_experts = num_experts\n\n    def forward(self, x):\n        B, T, D = x.shape\n        weights, topk_idx = self.router(x)  # weights: (B,T,E), topk_idx: (B,T,k)\n        flat_x = x.view(-1, D)  # (B*T, D)\n        flat_w = weights.view(-1, self.num_experts)  # (B*T, E)\n        out_flat = torch.zeros_like(flat_x)\n\n        # For each expert, find tokens routed to it (via topk indices)\n        # Build boolean mask for tokens assigned to each expert (if any of the k indices equals e)\n        # topk_idx == e -> (B,T,k) -> any(dim=-1) -> (B,T)\n        for e, expert in enumerate(self.experts):\n            # boolean mask (B,T) whether any of the k picks equals e\n            mask_e = (topk_idx == e).any(dim=-1).view(-1)  # (B*T,)\n            if not mask_e.any():\n                continue\n            inp = flat_x[mask_e]  # tokens assigned to this expert\n            out_e = expert(inp)   # (num_tokens_for_e, D)\n            w_e = flat_w[mask_e, e].unsqueeze(-1)  # (num_tokens_for_e,1)\n            out_flat[mask_e] += out_e * w_e\n\n        return out_flat.view(B, T, D)\n\n# -----------------------\n# Multi-Head Attention with RoPE & causal masking\n# -----------------------\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, dim, heads, dropout=0.1):\n        super().__init__()\n        assert dim % heads == 0, \"dim must be divisible by heads\"\n        self.dim = dim\n        self.heads = heads\n        self.head_dim = dim // heads\n        self.scale = self.head_dim ** -0.5\n        self.qkv = nn.Linear(dim, 3 * dim, bias=False)\n        self.proj = nn.Linear(dim, dim)\n        self.drop = nn.Dropout(dropout)\n        self.rope = RotaryEmbedding(self.head_dim)\n\n    def forward(self, x, attn_mask=None):\n        B, T, D = x.shape\n        qkv = self.qkv(x).chunk(3, dim=-1)\n        q, k, v = map(lambda t: t.view(B, T, self.heads, self.head_dim).transpose(1, 2), qkv)\n        # RoPE\n        cos, sin = self.rope(x, T)  # cos/sin shapes (T, head_dim)\n        cos = cos.view(1, 1, T, self.head_dim)\n        sin = sin.view(1, 1, T, self.head_dim)\n        q, k = apply_rotary_pos_emb(q, k, cos, sin)\n        # Attention\n        attn = (q @ k.transpose(-2, -1)) * self.scale  # (B, H, T, T)\n        # causal mask\n        causal_mask = torch.triu(torch.ones(T, T, device=x.device, dtype=torch.bool), diagonal=1)\n        attn = attn.masked_fill(causal_mask, float(\"-inf\"))\n        # padding mask\n        if attn_mask is not None:\n            pad_mask = (~attn_mask.bool()).view(B, 1, 1, T)  # True where padding\n            attn = attn.masked_fill(pad_mask, float(\"-inf\"))\n        attn = F.softmax(attn, dim=-1, dtype=torch.float32).to(q.dtype)\n        attn = self.drop(attn)\n        out = (attn @ v).transpose(1, 2).contiguous().view(B, T, D)\n        return self.proj(out)\n\n# -----------------------\n# Transformer Block & Model\n# -----------------------\nclass TransformerBlock(nn.Module):\n    def __init__(self, dim, heads, num_experts, k, dropout=0.1, moe_expansion=2.0):\n        super().__init__()\n        self.ln1 = nn.LayerNorm(dim)\n        self.attn = MultiHeadAttention(dim, heads, dropout)\n        self.ln2 = nn.LayerNorm(dim)\n        hidden_dim = int(dim * moe_expansion)\n        self.moe = MoELayer(dim, hidden_dim, num_experts, k, dropout)\n        self.drop = nn.Dropout(dropout)\n\n    def forward(self, x, attn_mask=None):\n        resid = x\n        x = self.ln1(x)\n        x = self.attn(x, attn_mask)\n        x = self.drop(x)\n        x = resid + x\n        resid = x\n        x = self.ln2(x)\n        x = self.moe(x)\n        x = self.drop(x)\n        x = resid + x\n        return x\n\nclass EnhancedGPTMoE(nn.Module):\n    def __init__(self, vocab_size, dim, depth, heads, num_experts, k, max_len, dropout, moe_expansion):\n        super().__init__()\n        self.max_len = max_len\n        self.tok = nn.Embedding(vocab_size, dim)\n        self.layers = nn.ModuleList([\n            TransformerBlock(dim, heads, num_experts, k, dropout, moe_expansion) for _ in range(depth)\n        ])\n        self.ln_f = nn.LayerNorm(dim)\n        self.head = nn.Linear(dim, vocab_size, bias=False)\n        # tie weights\n        self.head.weight = self.tok.weight\n        self.apply(self._init_weights)\n\n    def _init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            nn.init.normal_(m.weight, 0.0, 0.02)\n            if getattr(m, \"bias\", None) is not None:\n                nn.init.zeros_(m.bias)\n        elif isinstance(m, nn.Embedding):\n            nn.init.normal_(m.weight, 0.0, 0.02)\n        elif isinstance(m, nn.LayerNorm):\n            nn.init.ones_(m.weight); nn.init.zeros_(m.bias)\n\n    def forward(self, ids, attn_mask=None, targets=None, pad_id=None):\n        B, T = ids.shape\n        x = self.tok(ids)  # (B, T, D)\n        for blk in self.layers:\n            x = blk(x, attn_mask)\n        x = self.ln_f(x)\n        logits = self.head(x)  # (B, T, V)\n        loss = None\n        if targets is not None:\n            loss = F.cross_entropy(\n                logits.view(-1, logits.size(-1)),\n                targets.view(-1),\n                ignore_index=pad_id if pad_id is not None else -100\n            )\n        return logits, loss\n\n    @torch.no_grad()\n    def generate(self, ids, attn_mask=None, max_new_tokens=50, temp=0.7, top_p=0.9):\n        # ids: (B, cur_len)\n        for _ in range(max_new_tokens):\n            if ids.shape[1] > self.max_len:\n                ids = ids[:, -(self.max_len // 2):]\n                if attn_mask is not None:\n                    attn_mask = attn_mask[:, -(self.max_len // 2):]\n            logits, _ = self(ids, attn_mask)\n            logits = logits[:, -1, :] / max(temp, 1e-8)\n            if top_p < 1.0:\n                sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n                cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n                # mask tokens with cumulative prob > top_p\n                sorted_indices_to_remove = cumulative_probs > top_p\n                # keep first token that exceeds threshold\n                sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n                sorted_indices_to_remove[..., 0] = False\n                indices_to_remove = sorted_indices[sorted_indices_to_remove]\n                logits.scatter_(1, indices_to_remove, float(\"-inf\"))\n            probs = F.softmax(logits, dim=-1)\n            next_token = torch.multinomial(probs, num_samples=1)  # (B,1)\n            ids = torch.cat([ids, next_token], dim=1)\n            if attn_mask is not None:\n                attn_mask = torch.cat([attn_mask, torch.ones((attn_mask.shape[0], 1), device=ids.device, dtype=attn_mask.dtype)], dim=1)\n        return ids\n\n# -----------------------\n# Data: tokenizer, dataset, dataloader\n# -----------------------\ndef setup_data(seq_len=256, fraction=\"train[:5%]\"):\n    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n    tokenizer.pad_token = tokenizer.eos_token\n\n    ds = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=fraction)\n    ds = ds.filter(lambda e: len(e[\"text\"].strip()) > 30)\n\n    def tok_fn(batch):\n        return tokenizer(batch[\"text\"], truncation=True, max_length=seq_len, padding=\"max_length\")\n\n    ds_tok = ds.map(tok_fn, batched=True, remove_columns=[\"text\"])\n    ds_tok = ds_tok.filter(lambda e: sum(e[\"attention_mask\"]) > 10)\n    ds_tok.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n\n    dl = DataLoader(ds_tok, batch_size=TRAINING_CONFIG[\"batch_size\"], shuffle=True)\n    return tokenizer, dl\n\n# -----------------------\n# Training loop (OOM-safe + AMP)\n# -----------------------\ndef train():\n    seq_len = TRAINING_CONFIG[\"seq_len\"]\n    tokenizer, dataloader = setup_data(seq_len)\n    vocab_size = len(tokenizer)\n\n    model = EnhancedGPTMoE(\n        vocab_size=vocab_size,\n        dim=MODEL_CONFIG[\"dim\"],\n        depth=MODEL_CONFIG[\"depth\"],\n        heads=MODEL_CONFIG[\"heads\"],\n        num_experts=MODEL_CONFIG[\"num_experts\"],\n        k=MODEL_CONFIG[\"k\"],\n        max_len=MODEL_CONFIG[\"max_len\"],\n        dropout=MODEL_CONFIG[\"dropout\"],\n        moe_expansion=MODEL_CONFIG[\"moe_expansion\"],\n    ).to(device)\n\n    n_params = sum(p.numel() for p in model.parameters())\n    print(f\"Model parameters: {n_params:,}\")\n\n    optimizer = torch.optim.AdamW(\n        model.parameters(),\n        lr=TRAINING_CONFIG[\"lr\"],\n        betas=TRAINING_CONFIG[\"betas\"],\n        weight_decay=TRAINING_CONFIG[\"weight_decay\"]\n    )\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n        optimizer, T_max=TRAINING_CONFIG[\"cosine_Tmax\"], eta_min=1e-5\n    )\n    scaler = GradScaler()\n\n    model.train()\n    empty_every = TRAINING_CONFIG[\"empty_cache_every\"]\n\n    for epoch in range(1, TRAINING_CONFIG[\"epochs\"] + 1):\n        total_loss = 0.0\n        steps = 0\n        for i, batch in enumerate(dataloader, start=1):\n            input_ids = batch[\"input_ids\"].to(device, non_blocking=True)\n            attn_mask = batch[\"attention_mask\"].to(device, non_blocking=True)\n\n            # Shift tokens: predict next token\n            targets = input_ids[:, 1:].contiguous()\n            input_ids = input_ids[:, :-1].contiguous()\n            attn_mask = attn_mask[:, :-1].contiguous()\n\n            optimizer.zero_grad(set_to_none=True)\n            try:\n                # autocast device type\n                with autocast(device_type=\"cuda\" if device == \"cuda\" else \"cpu\"):\n                    logits, loss = model(input_ids, attn_mask, targets, pad_id=tokenizer.pad_token_id)\n\n                if loss is None or torch.isnan(loss):\n                    raise RuntimeError(\"Invalid loss (None or NaN)\")\n\n                scaler.scale(loss).backward()\n                scaler.unscale_(optimizer)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n                scaler.step(optimizer)\n                scaler.update()\n\n                total_loss += loss.item()\n                steps += 1\n\n            except RuntimeError as e:\n                if \"out of memory\" in str(e).lower():\n                    print(\"GPU OOM - skipping batch safely...\")\n                    optimizer.zero_grad(set_to_none=True)\n                    if torch.cuda.is_available():\n                        torch.cuda.empty_cache()\n                    continue\n                else:\n                    raise\n\n            if i % 100 == 0 and steps > 0:\n                print(f\"Epoch {epoch} Step {i} Loss {loss.item():.4f}\")\n\n            if empty_every and (i % empty_every == 0) and torch.cuda.is_available():\n                torch.cuda.empty_cache()\n\n        if steps > 0:\n            avg = total_loss / steps\n            print(f\"Epoch {epoch}/{TRAINING_CONFIG['epochs']} Avg Loss: {avg:.4f}\")\n        scheduler.step()\n\n    return model, tokenizer\n\n# -----------------------\n# Inference helper\n# -----------------------\ndef generate_text(model, tokenizer, prompt=\"Once upon a time\", max_new_tokens=50, temp=0.7, top_p=0.9):\n    model.eval()\n    with torch.no_grad():\n        ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n        attn = torch.ones_like(ids).to(device)\n        out_ids = model.generate(ids, attn, max_new_tokens=max_new_tokens, temp=temp, top_p=top_p)\n        # out_ids is tensor (1, L)\n        return tokenizer.decode(out_ids[0].tolist(), skip_special_tokens=True)\n\n# -----------------------\n# Main\n# -----------------------\nif __name__ == \"__main__\":\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n    model, tokenizer = train()\n    sample = generate_text(model, tokenizer, \"Hello world\", max_new_tokens=40)\n    print(\"\\nGenerated sample:\\n\", sample)\n\n    # Save a checkpoint\n    save_path = \"enhanced_gpt_moe_checkpoint.pt\"\n    torch.save({\n        \"model_state_dict\": model.state_dict(),\n        \"model_config\": MODEL_CONFIG,\n        \"vocab_size\": len(tokenizer)\n    }, save_path)\n    print(f\"Saved checkpoint to {save_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T15:49:49.090119Z","iopub.execute_input":"2025-08-08T15:49:49.091097Z","iopub.status.idle":"2025-08-08T16:13:17.581319Z","shell.execute_reply.started":"2025-08-08T15:49:49.091068Z","shell.execute_reply":"2025-08-08T16:13:17.580350Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nModel parameters: 185,185,792\nEpoch 1 Step 100 Loss 7.4320\nEpoch 1 Step 200 Loss 7.2516\nEpoch 1 Step 300 Loss 7.1622\nEpoch 1 Step 400 Loss 6.3386\nEpoch 1 Step 500 Loss 7.3772\nEpoch 1 Step 600 Loss 6.2084\nEpoch 1 Step 700 Loss 7.1914\nEpoch 1 Step 800 Loss 7.0790\nEpoch 1 Step 900 Loss 7.5319\nEpoch 1/6 Avg Loss: 7.0181\nEpoch 2 Step 100 Loss 6.1176\nEpoch 2 Step 200 Loss 7.1716\nEpoch 2 Step 300 Loss 6.5150\nEpoch 2 Step 400 Loss 6.4436\nEpoch 2 Step 500 Loss 4.7971\nEpoch 2 Step 600 Loss 5.5999\nEpoch 2 Step 700 Loss 6.1599\nEpoch 2 Step 800 Loss 6.7628\nEpoch 2 Step 900 Loss 7.5145\nEpoch 2/6 Avg Loss: 6.2372\nEpoch 3 Step 100 Loss 5.9019\nEpoch 3 Step 200 Loss 5.9103\nEpoch 3 Step 300 Loss 6.2394\nEpoch 3 Step 400 Loss 6.3933\nEpoch 3 Step 500 Loss 6.2708\nEpoch 3 Step 600 Loss 6.4812\nEpoch 3 Step 700 Loss 6.5506\nEpoch 3 Step 800 Loss 5.3172\nEpoch 3 Step 900 Loss 2.4263\nEpoch 3/6 Avg Loss: 5.9500\nEpoch 4 Step 100 Loss 7.5102\nEpoch 4 Step 200 Loss 6.3402\nEpoch 4 Step 300 Loss 6.3631\nEpoch 4 Step 400 Loss 6.0578\nEpoch 4 Step 500 Loss 6.6877\nEpoch 4 Step 600 Loss 6.0659\nEpoch 4 Step 700 Loss 6.2686\nEpoch 4 Step 800 Loss 5.5184\nEpoch 4 Step 900 Loss 6.2946\nEpoch 4/6 Avg Loss: 5.6861\nEpoch 5 Step 100 Loss 5.7916\nEpoch 5 Step 200 Loss 4.7363\nEpoch 5 Step 300 Loss 5.5268\nEpoch 5 Step 400 Loss 6.9508\nEpoch 5 Step 500 Loss 6.0246\nEpoch 5 Step 600 Loss 6.0842\nEpoch 5 Step 700 Loss 5.7434\nEpoch 5 Step 800 Loss 6.1656\nEpoch 5 Step 900 Loss 6.2255\nEpoch 5/6 Avg Loss: 5.4276\nEpoch 6 Step 100 Loss 4.7239\nEpoch 6 Step 200 Loss 6.0386\nEpoch 6 Step 300 Loss 6.0645\nEpoch 6 Step 400 Loss 5.0716\nEpoch 6 Step 500 Loss 4.7704\nEpoch 6 Step 600 Loss 5.4653\nEpoch 6 Step 700 Loss 5.9463\nEpoch 6 Step 800 Loss 6.1688\nEpoch 6 Step 900 Loss 5.4699\nEpoch 6/6 Avg Loss: 5.2048\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_150/4087561598.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Hello world\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nGenerated sample:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_150/4087561598.py\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(model, tokenizer, prompt, max_new_tokens, temp, top_p)\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0mout_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m         \u001b[0;31m# out_ids is tensor (1, L)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_150/4087561598.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, ids, attn_mask, max_new_tokens, temp, top_p)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0msorted_indices_to_remove\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mindices_to_remove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msorted_indices_to_remove\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_to_remove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mnext_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (B,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as self tensor"],"ename":"RuntimeError","evalue":"Index tensor must have the same number of dimensions as self tensor","output_type":"error"}],"execution_count":3}]}