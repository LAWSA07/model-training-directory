{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c9d9234",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-16T10:07:36.972148Z",
     "iopub.status.busy": "2025-08-16T10:07:36.971894Z",
     "iopub.status.idle": "2025-08-16T16:06:49.367756Z",
     "shell.execute_reply": "2025-08-16T16:06:49.367061Z"
    },
    "papermill": {
     "duration": 21552.400273,
     "end_time": "2025-08-16T16:06:49.369061",
     "exception": false,
     "start_time": "2025-08-16T10:07:36.968788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training lgb_2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb_2025 OOF AUC: 0.96913\n",
      "Training xgb_2025\n",
      "xgb_2025 OOF AUC: 0.96870\n",
      "Training cat_2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_2025 OOF AUC: 0.96649\n",
      "Training lgb_2067\n",
      "lgb_2067 OOF AUC: 0.96915\n",
      "Training xgb_2067\n",
      "xgb_2067 OOF AUC: 0.96867\n",
      "Training cat_2067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_2067 OOF AUC: 0.96650\n",
      "Training lgb_2148\n",
      "lgb_2148 OOF AUC: 0.96908\n",
      "Training xgb_2148\n",
      "xgb_2148 OOF AUC: 0.96867\n",
      "Training cat_2148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_2148 OOF AUC: 0.96651\n",
      "Training lgb_2481\n",
      "lgb_2481 OOF AUC: 0.96912\n",
      "Training xgb_2481\n",
      "xgb_2481 OOF AUC: 0.96866\n",
      "Training cat_2481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_2481 OOF AUC: 0.96657\n",
      "Training lgb_2814\n",
      "lgb_2814 OOF AUC: 0.96913\n",
      "Training xgb_2814\n",
      "xgb_2814 OOF AUC: 0.96866\n",
      "Training cat_2814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "Default metric period is 5 because AUC is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_2814 OOF AUC: 0.96650\n",
      "Meta LR AUC: 0.9695506595992953\n",
      "Weights: {'base_w': '0.5000', 'meta_lr': '0.5000'}\n",
      "Pre-cal AUC: 0.96935987653169\n",
      "Cal AUC: 0.9694171833696903\n",
      "Final AUC: 0.9694171833696903\n",
      "Saved submission_v28_2.csv Final OOF AUC: 0.9694171833696903\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# HyperBoost V28.2: Cleaned & Hardened Ultra Ensemble\n",
    "# - Single per-fold imputation\n",
    "# - Compatible XGBoost early stopping\n",
    "# - Warnings instead of hard assert for no categoricals\n",
    "# - Fixed month mapping to avoid Categorical fillna error\n",
    "# =============================================================================\n",
    "\n",
    "import os, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from scipy.optimize import minimize\n",
    "from typing import Optional\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    DATA_PATH: str = \"/kaggle/input/playground-series-s5e8\"\n",
    "    EXTERNAL_DATA_PATH: str = \"/kaggle/input/bankdatset/bank1.csv\"\n",
    "    OUTPUT_NAME: str = \"submission_v28_2.csv\"\n",
    "    SEED: int = 2025\n",
    "    N_SPLITS: int = 10\n",
    "    N_ESTIMATORS: int = 10000\n",
    "    EARLY_STOP: int = 500\n",
    "    USE_GPU: bool = True\n",
    "    SEEDS: tuple = (0, 42, 123, 456, 789)\n",
    "    USE_EXTERNAL: bool = True\n",
    "    USE_LGB: bool = True\n",
    "    USE_XGB: bool = True\n",
    "    USE_CAT: bool = True\n",
    "    USE_META_LR: bool = True\n",
    "    BLEND_OPTIMIZE: bool = True\n",
    "    USE_CALIBRATION: bool = True\n",
    "\n",
    "CFG = Config()\n",
    "\n",
    "def seed_all(seed=CFG.SEED):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_all()\n",
    "\n",
    "def read_data():\n",
    "    train = pd.read_csv(f\"{CFG.DATA_PATH}/train.csv\")\n",
    "    test  = pd.read_csv(f\"{CFG.DATA_PATH}/test.csv\")\n",
    "    if 'duration' not in train or 'duration' not in test:\n",
    "        raise ValueError(\"Both train and test must contain 'duration'\")\n",
    "    return train, test\n",
    "\n",
    "def enhanced_features(df):\n",
    "    out = df.copy()\n",
    "    month_map = dict(zip(\n",
    "        ['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec'],\n",
    "        range(1,13)\n",
    "    ))\n",
    "    if 'month' in out:\n",
    "        # Fix: convert to str before mapping to avoid Categorical fillna error\n",
    "        month_str = out['month'].astype(str).str.lower()\n",
    "        out['month_num'] = month_str.map(month_map).fillna(0).astype(int)\n",
    "        out.drop(columns=['month'], inplace=True)\n",
    "        out['month_sin'] = np.sin(2*np.pi*out['month_num']/12)\n",
    "        out['month_cos'] = np.cos(2*np.pi*out['month_num']/12)\n",
    "    if 'balance' in out and 'age' in out:\n",
    "        out['balance_per_age'] = out['balance'] / (out['age'].replace(0, np.nan))\n",
    "    if 'age' in out and 'campaign' in out:\n",
    "        out['age_x_campaign'] = out['age'] * out['campaign']\n",
    "    for c in ['age','campaign','balance','duration']:\n",
    "        if c in out:\n",
    "            out[f'{c}_sq'] = out[c]**2\n",
    "            out[f'{c}_sqrt'] = np.sqrt(np.abs(out[c]))\n",
    "    return out\n",
    "\n",
    "def add_external_data_features(df, external_df):\n",
    "    if external_df is None:\n",
    "        return df\n",
    "    df_ext = df.copy()\n",
    "    def norm_str(s):\n",
    "        s = str(s).lower().strip()\n",
    "        return ' '.join(s.replace('.', '').replace('-', ' ').split())\n",
    "    ext = external_df.copy()\n",
    "    for col in ext.select_dtypes(include='object'):\n",
    "        ext[col] = ext[col].apply(norm_str)\n",
    "    for col in df_ext.select_dtypes(include='object'):\n",
    "        df_ext[col] = df_ext[col].apply(norm_str).astype('category')\n",
    "    common = [c for c in df_ext.columns if c in ext.columns and df_ext[c].dtype.name=='category']\n",
    "    for c in common:\n",
    "        vc = ext[c].value_counts()\n",
    "        freq = (vc / vc.sum()).astype(float)\n",
    "        prior = 1.0/max(1, vc.size)\n",
    "        smooth = ((vc + 20*prior)/(vc.sum()+20)).astype(float)\n",
    "        cnt_vals = df_ext[c].astype(str).map(vc).fillna(0).astype(float)\n",
    "        hi = np.percentile(cnt_vals, 99)\n",
    "        df_ext[f'{c}_ext_cnt'] = np.clip(cnt_vals, 0, hi)\n",
    "        df_ext[f'{c}_ext_freq'] = df_ext[c].astype(str).map(freq).fillna(0.0).astype(float)\n",
    "        df_ext[f'{c}_ext_smooth'] = df_ext[c].astype(str).map(smooth).fillna(prior).astype(float)\n",
    "    return df_ext\n",
    "\n",
    "def bayesian_target_encoding(X_tr, X_va, X_te, y_tr, cat_cols, alpha=10):\n",
    "    prior = y_tr.mean()\n",
    "    te_cols = []\n",
    "    for c in cat_cols:\n",
    "        if c not in X_tr: continue\n",
    "        stats = y_tr.groupby(X_tr[c]).agg(['mean','count'])\n",
    "        smooth = (stats['mean']*stats['count'] + prior*alpha) / (stats['count'] + alpha)\n",
    "        for df in (X_tr,X_va,X_te):\n",
    "            if c in df:\n",
    "                vals = df[c].map(smooth).astype(float).fillna(prior)\n",
    "                df[f'{c}_te'] = vals.values\n",
    "                te_cols.append(f'{c}_te')\n",
    "        for df in (X_tr,X_va,X_te):\n",
    "            df.drop(columns=[c], inplace=True, errors='ignore')\n",
    "    return X_tr, X_va, X_te, te_cols\n",
    "\n",
    "def add_freq_encoding(X_tr, X_va, X_te, cat_cols):\n",
    "    fe_cols = []\n",
    "    for c in cat_cols:\n",
    "        if c not in X_tr: continue\n",
    "        freq = (X_tr[c].value_counts()/len(X_tr)).astype(float)\n",
    "        for df in (X_tr,X_va,X_te):\n",
    "            vals = df[c].map(freq).astype(float).fillna(0.0)\n",
    "            df[f'{c}_freq'] = vals.values\n",
    "            fe_cols.append(f'{c}_freq')\n",
    "    return X_tr, X_va, X_te, fe_cols\n",
    "\n",
    "def impute_only(X_tr, X_va, X_te):\n",
    "    cols = X_tr.select_dtypes(include='number').columns\n",
    "    imp = SimpleImputer(strategy='median')\n",
    "    X_tr[cols] = imp.fit_transform(X_tr[cols])\n",
    "    X_va[cols] = imp.transform(X_va[cols])\n",
    "    X_te[cols] = imp.transform(X_te[cols])\n",
    "    return X_tr, X_va, X_te\n",
    "\n",
    "def get_models():\n",
    "    models = []\n",
    "    for offset in CFG.SEEDS:\n",
    "        seed = CFG.SEED + offset\n",
    "        if CFG.USE_LGB:\n",
    "            models.append((f'lgb_{seed}', lgb.LGBMClassifier(\n",
    "                objective='binary', metric='auc',\n",
    "                n_estimators=CFG.N_ESTIMATORS, learning_rate=0.015,\n",
    "                num_leaves=127, subsample=0.85, colsample_bytree=0.85,\n",
    "                device='gpu' if CFG.USE_GPU else 'cpu',\n",
    "                random_state=seed, verbosity=-1\n",
    "            )))\n",
    "        if CFG.USE_XGB:\n",
    "            models.append((f'xgb_{seed}', xgb.XGBClassifier(\n",
    "                objective='binary:logistic', eval_metric='auc',\n",
    "                n_estimators=CFG.N_ESTIMATORS, learning_rate=0.015,\n",
    "                max_depth=8, subsample=0.85, colsample_bytree=0.85,\n",
    "                tree_method='gpu_hist' if CFG.USE_GPU else 'hist',\n",
    "                random_state=seed\n",
    "            )))\n",
    "        if CFG.USE_CAT:\n",
    "            models.append((f'cat_{seed}', CatBoostClassifier(\n",
    "                iterations=CFG.N_ESTIMATORS, learning_rate=0.015,\n",
    "                depth=8, l2_leaf_reg=5, eval_metric='AUC',\n",
    "                task_type='GPU' if CFG.USE_GPU else 'CPU',\n",
    "                random_seed=seed, od_type='Iter', od_wait=CFG.EARLY_STOP,\n",
    "                verbose=False\n",
    "            )))\n",
    "    return models\n",
    "\n",
    "def train_base_models(X, y, T, cat_cols):\n",
    "    models = get_models()\n",
    "    oof = np.zeros((len(X), len(models)))\n",
    "    tst = np.zeros((len(T), len(models)))\n",
    "    aucs = []\n",
    "    folds = StratifiedKFold(n_splits=CFG.N_SPLITS, shuffle=True, random_state=CFG.SEED)\n",
    "    for i,(name,model) in enumerate(models):\n",
    "        print(f\"Training {name}\")\n",
    "        oof_pred = np.zeros(len(X)); tst_pred = np.zeros(len(T))\n",
    "        for tr,va in folds.split(X,y):\n",
    "            X_tr, X_va = X.iloc[tr].copy(), X.iloc[va].copy()\n",
    "            y_tr, y_va = y.iloc[tr], y.iloc[va]\n",
    "            X_te = T.copy()\n",
    "            X_tr, X_va, X_te, fe = add_freq_encoding(X_tr,X_va,X_te,cat_cols)\n",
    "            X_tr, X_va, X_te, te = bayesian_target_encoding(X_tr,X_va,X_te,y_tr,cat_cols)\n",
    "            if not te:\n",
    "                warnings.warn(\"No TE columns created\")\n",
    "            X_tr, X_va, X_te = impute_only(X_tr,X_va,X_te)\n",
    "            X_va = X_va.reindex(columns=X_tr.columns, fill_value=0)\n",
    "            X_te = X_te.reindex(columns=X_tr.columns, fill_value=0)\n",
    "            if name.startswith('lgb'):\n",
    "                model.fit(X_tr,y_tr,eval_set=[(X_va,y_va)],\n",
    "                          callbacks=[lgb.early_stopping(CFG.EARLY_STOP,verbose=False)])\n",
    "            elif name.startswith('xgb'):\n",
    "                model.fit(X_tr,y_tr,eval_set=[(X_va,y_va)],\n",
    "                          early_stopping_rounds=CFG.EARLY_STOP, verbose=False)\n",
    "            else:\n",
    "                model.fit(X_tr,y_tr,eval_set=[(X_va,y_va)],use_best_model=True)\n",
    "            oof_pred[va] = model.predict_proba(X_va)[:,1]\n",
    "            tst_pred += model.predict_proba(X_te)[:,1] / CFG.N_SPLITS\n",
    "        auc = roc_auc_score(y,oof_pred)\n",
    "        print(f\"{name} OOF AUC: {auc:.5f}\")\n",
    "        oof[:,i] = oof_pred\n",
    "        tst[:,i] = tst_pred\n",
    "        aucs.append(auc)\n",
    "    return oof,tst,aucs\n",
    "\n",
    "def blend_and_stack(oof,tst,y,aucs):\n",
    "    comps,names = [],[]\n",
    "    w = np.array(aucs) / sum(aucs)\n",
    "    comps.append((oof @ w, tst @ w)); names.append('base_w')\n",
    "    if CFG.USE_META_LR:\n",
    "        meta_oof = np.zeros(len(y))\n",
    "        folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=CFG.SEED+1)\n",
    "        for tr,va in folds.split(oof,y):\n",
    "            m = LogisticRegressionCV(Cs=10, cv=3, scoring='roc_auc', max_iter=2000, n_jobs=-1, random_state=CFG.SEED+1)\n",
    "            m.fit(oof[tr],y.iloc[tr])\n",
    "            meta_oof[va] = m.predict_proba(oof[va])[:,1]\n",
    "        m.fit(oof,y)\n",
    "        meta_tst = m.predict_proba(tst)[:,1]\n",
    "        comps.append((meta_oof,meta_tst)); names.append('meta_lr')\n",
    "        print(\"Meta LR AUC:\", roc_auc_score(y,meta_oof))\n",
    "    coof = np.column_stack([c[0] for c in comps])\n",
    "    cst = np.column_stack([c[1] for c in comps])\n",
    "    def obj(w):\n",
    "        w = np.clip(w,0,1); w /= w.sum()\n",
    "        return -roc_auc_score(y, coof @ w)\n",
    "    bounds = [(0.01,0.8)] * coof.shape[1]\n",
    "    cons = [{'type':'eq', 'fun':lambda w: w.sum()-1}]\n",
    "    res = minimize(obj, np.ones(coof.shape[1])/coof.shape[1], method='SLSQP', bounds=bounds, constraints=cons)\n",
    "    w_opt = res.x / res.x.sum()\n",
    "    print(\"Weights:\", dict(zip(names, [f\"{v:.4f}\" for v in w_opt])))\n",
    "    final_oof = coof @ w_opt\n",
    "    final_tst = cst @ w_opt\n",
    "    pre = roc_auc_score(y, final_oof)\n",
    "    print(\"Pre-cal AUC:\", pre)\n",
    "    if CFG.USE_CALIBRATION:\n",
    "        iso = IsotonicRegression(out_of_bounds='clip')\n",
    "        iso.fit(final_oof, y)\n",
    "        cal_oof = iso.transform(final_oof)\n",
    "        cal_tst = iso.transform(final_tst)\n",
    "        post = roc_auc_score(y, cal_oof)\n",
    "        if post >= pre:\n",
    "            final_oof = cal_oof\n",
    "            final_tst = cal_tst\n",
    "            print(\"Cal AUC:\", post)\n",
    "        else:\n",
    "            print(\"Cal skipped\")\n",
    "        final_auc = post if post >= pre else pre\n",
    "    else:\n",
    "        final_auc = pre\n",
    "    print(\"Final AUC:\", final_auc)\n",
    "    return final_tst, final_auc\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train, test = read_data()\n",
    "    y = train['y'].astype(int)\n",
    "    X = train.drop(columns=['id','y']).copy()\n",
    "    T = test.drop(columns=['id']).copy()\n",
    "    for c in X.select_dtypes(include='object'):\n",
    "        X[c] = X[c].str.lower().fillna('unknown').astype('category')\n",
    "        T[c] = T[c].str.lower().fillna('unknown').astype('category')\n",
    "    X = enhanced_features(X)\n",
    "    T = enhanced_features(T)\n",
    "    if CFG.USE_EXTERNAL:\n",
    "        try:\n",
    "            ext = pd.read_csv(CFG.EXTERNAL_DATA_PATH)\n",
    "            X = add_external_data_features(X, ext)\n",
    "            T = add_external_data_features(T, ext)\n",
    "        except:\n",
    "            print(\"Skip external\")\n",
    "    T = T.reindex(columns=X.columns, fill_value=0)\n",
    "    assert list(X.columns) == list(T.columns), \"Columns mismatch\"\n",
    "    cat_cols = [c for c in X.columns if X[c].dtype.name in ('category','object')]\n",
    "    if not cat_cols:\n",
    "        warnings.warn(\"No categoricals found\")\n",
    "    oof, tst, aucs = train_base_models(X, y, T, cat_cols)\n",
    "    preds, auc = blend_and_stack(oof, tst, y, aucs)\n",
    "    sub = pd.DataFrame({'id': test['id'].values, 'y': preds})\n",
    "    sub.to_csv(CFG.OUTPUT_NAME, index=False)\n",
    "    print(\"Saved\", CFG.OUTPUT_NAME, \"Final OOF AUC:\", auc)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12937777,
     "sourceId": 91719,
     "sourceType": "competition"
    },
    {
     "datasetId": 8072890,
     "sourceId": 12770118,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21559.161617,
   "end_time": "2025-08-16T16:06:52.108968",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-16T10:07:32.947351",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
